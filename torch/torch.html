<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />

<title>Débuter avec torch</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-bienvenues" class="section level2">
<h2>Bienvenu(e)s !</h2>
<p>Aujourd’hui, on va vous montrer comment faire de l’apprentissage automatique avec <code>torch</code> et son API de haut niveau, <code>luz</code>.</p>
<div id="section-torch" class="section level3">
<h3><code>torch</code></h3>
<p><a href="http:/torch.mlverse.org"><code>torch</code></a> torch est un cadre natif R pour le calcul rapide de tableaux avec différenciation automatique et de riches fonctionnalités de réseaux neuronaux.</p>
<p><code>torch</code> est implémenté en R et C++, tout en déléguant à LibTorch pour les opérations de plus bas niveau.</p>
<div class="figure">
<img src="torch_arch.png" title="torch architecture" alt="" />
<p class="caption"><img src="images/torch_arch.png" /></p>
</div>
</div>
<div id="section-luz" class="section level3">
<h3><code>luz</code></h3>
<p>Ce que <code>keras</code> est à <code>tensorflow</code> – une API de haut niveau qui uniformise et instrumente l’apprentissage – <code>luz</code> est à <code>torch</code>. Alors que tout peut être accompli avec <code>torch</code> seul, <code>luz</code> peut être d’une aide énorme, en tant que</p>
<ul>
<li><p>fournissant une interface déclarative à l’apprentissage, assez semblable à <em>keras</em></p></li>
<li><p>éliminant du code générique</p></li>
<li><p>surveillant des métriques souvent utilisées en science de données, et permettant aux utilisateurs d’en définir ses propres mesures</p></li>
<li><p>fournissant un ensemble de <em>rappels</em> prêts à l’emploi afin de contrôler l’apprentissage, sauvegarder l’état du modèle, etc.</p></li>
<li><p>définant une interface simple pour créer vos propres rappels</p></li>
</ul>
</div>
<div id="section-écosystème" class="section level3">
<h3>Écosystème</h3>
<ul>
<li><p><a href="https:/github.com/mlverse/torch">torch</a></p></li>
<li><p><a href="https:/github.com/mlverse/luz">luz</a></p></li>
<li><p><a href="https:/github.com/mlverse/torchvision">torchvision</a></p></li>
<li><p><a href="https:/github.com/mlverse/torchdatasets">torchdatasets</a></p></li>
<li><p><a href="https:/github.com/mlverse/tabnet">tabnet</a></p></li>
<li><p>… et plus encore !</p></li>
</ul>
</div>
<div id="section-nos-objectifs-pour-aujourdhui" class="section level3">
<h3>Nos objectifs pour aujourd’hui</h3>
<ol style="list-style-type: decimal">
<li><p>Comprendre et utiliser les tenseurs <code>torch</code> et les modules de réseaux neuronaux ; comprendre et appliquer la différenciation automatique.</p></li>
<li><p>Utiliser <code>luz</code> pour entraîner des réseaux neuronaux de manière déclarative.</p></li>
<li><p>Démarrer avec la prévision des séries temporelles avec <code>torch</code>.</p></li>
</ol>
</div>
<div id="section-prerequisites" class="section level3">
<h3>Prerequisites</h3>
<p>Pour suivre ce tutoriel, vous devez installer les paquets suivants :</p>
</div>
</div>
<div id="section-torch-tenseurs-modules-and-autograd" class="section level2">
<h2><code>torch</code> tenseurs, modules, and autograd</h2>
<div id="section-tenseurs" class="section level3">
<h3>Tenseurs</h3>
<div id="section-créer-des-tenseurs" class="section level4">
<h4>Créer des tenseurs</h4>
<div id="section-méthode-1-a-partir-des-valeurs-r" class="section level5">
<h5>Méthode 1 : A partir des valeurs R</h5>
<p>Les tenseurs peuvent être créés directement à partir de valeurs R en utilisant torch_tensor(). En option, nous pouvons définir les attributs du tenseur, y compris le type de données, le dispositif sur lequel il vit, et plus encore.</p>
<p>Ici, nous créons des tenseurs unidimensionnels (donc, des vecteurs) :</p>
<pre class="r"><code>torch_tensor(1)
torch_tensor(1, dtype = torch_int())
torch_tensor(1, device = &quot;cuda&quot;)

torch_tensor(c(1, 2, 3)) # tenseur flottant</code></pre>
<p>Des tenseurs bidimensionnels peuvent être créés à partir de matrices R.</p>
<pre class="r"><code>torch_tensor(matrix(1:9, ncol = 3)) # tenseur entier
torch_tensor(matrix(1:9, ncol = 3))$to(dtype = torch_float()) # convertir en flottant

torch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))</code></pre>
<p>Des tenseurs de plus haute dimension peuvent être créés à partir de tableaux R, mais il est normalement plus facile d’utiliser les fonctions de création en masse.</p>
</div>
<div id="section-méthode-2-fonctions-de-création-en-masse." class="section level5">
<h5>Méthode 2 : Fonctions de création en masse.</h5>
<p>Des tenseurs multidimensionnels suivant un certain modèle définissable sont créés en passant en tant qu’argument la dimensionnalité souhaitée. Quelques exemples (il en existe d’autres) :</p>
<pre class="r"><code>torch_zeros(c(3, 3))
torch_rand(c(3, 3))</code></pre>
<p>Un autre type de fonction souvent utilisé consiste à spécifier la plage souhaitée :</p>
<pre class="r"><code>torch_arange(1, 9)
torch_logspace(start = 0.1, end = 1.0, steps = 5)</code></pre>
</div>
</div>
<div id="section-reconversion-en-r" class="section level4">
<h4>Reconversion en R</h4>
<p>Les tenseurs sont reconvertis en R en utilisant <code>as.numeric()</code>, <code>as.matrix()</code>, ou <code>as.array()</code> :</p>
<pre class="r"><code>torch_tensor(2) %&gt;% as.numeric()

torch_ones(c(2, 2)) %&gt;% as.matrix() 

torch_ones(c(2, 2, 2)) %&gt;% as.array() </code></pre>
</div>
<div id="section-opérations-sur-les-tenseurs" class="section level4">
<h4>Opérations sur les tenseurs</h4>
<p>Il y a un grand nombre d’opérations qui peuvent être effectuées sur les tenseurs. En général, il existe une paire de fonction (non associée à un objet) et de méthode correspondante (“appartenant” à une instance de tenseur) qui font la même chose :</p>
<pre class="r"><code>t1 &lt;- torch_tensor(c(1, 2, 3))
t2 &lt;- torch_tensor(c(1, 2, 3))

torch_add(t1, t2)
t1$add(t2)</code></pre>
<p>Dans les deux cas, les tenseurs originaux ne sont pas modifiés du tout ; par contre, un nouvel objet est créé. Normalement, vous alliez simplement l’assigner à une nouvelle variable :</p>
<pre class="r"><code>t3 &lt;- t1$add(t2)

t1
t3</code></pre>
<p>Dans les rares cas où vous devez modifier le tenseur original, vous pouvez utiliser les variantes trait de soulignement correspondantes :</p>
<pre class="r"><code>t1$add_(t2)
t1</code></pre>
<p>Voici quelques-unes des nombreuses opérations matricielles disponibles. <code>$mul()</code> effectue une multiplication par éléments ; <code>$matmul()</code> effectue une multiplication matricielle ; <code>$dot()</code> calcule le produit scalaire :</p>
<pre class="r"><code>t1$mul(t2)

# fonctionnent tous les deux(en torch, il n&#39;ya pas de concept de vecteur ligne vs colonne)
t1$matmul(t2)
t1$t()$matmul(t2)

t1$dot(t2)</code></pre>
<p>Vous pouvez voir que <code>torch</code> ne fait pas de distinction entre les vecteurs ligne et colonne. Ci-dessus, <code>$t()</code> transpose le vecteur <code>t1</code>, mais la multiplication matricielle fonctionnera sans.</p>
</div>
<div id="section-remodeler-des-tenseurs" class="section level4">
<h4>Remodeler des tenseurs</h4>
<p>Souvent, vous aurez besoin de remodeler un tenseur. Parmi les opérations les plus courantes, citons <code>$squeeze()</code> et <code>$unsqueeze()</code>. La première supprime une dimension singleton à la position spécifiée (où singleton signifie que la dimension est de longueur 1) :</p>
<pre class="r"><code>t1 &lt;- torch_randn(c(1, 2, 3, 4))
t1

t1$squeeze(1)</code></pre>
<p>Le dernier, par contre, ajoute une dimension singleton :</p>
<pre class="r"><code>t1$unsqueeze(4)</code></pre>
<p>Cela ne fonctionne que pour les dimensions singleton. <code>$view()</code>, en revanche, fonctionne pour un remodelage arbitraire, à condition que le nombre d’éléments le permette. <code>t1</code>, ci-dessus, à 24 valeurs, qui pourraient aussi bien être arrangées en 6x4 ou 1x24 :</p>
<pre class="r"><code>t2 &lt;- t1$view(c(6, 4))

t3 &lt;- t1$view(24)</code></pre>
<p>En fait, <code>$view()</code> ne crée pas réellement un tenseur nouveau ; au lieu de cela, cette méthode arrange pour que la nouvelle référence se réfère toujours au même emplacement en mémoire, et stocke juste quelques métadonnées qui indiquent à <code>torch</code> comment interpréter les octets respectifs. Il y a des situations où <code>$view()</code> ne peut pas être utilisé ; dans ce cas, vous pouvez toujours utiliser <code>$reshape()</code> à sa place. Contrairement à <code>$view()</code>, <code>$reshape()</code> fera une copie physique si nécessaire.</p>
</div>
<div id="section-indexation-et-découpage-en-tranches" class="section level4">
<h4>Indexation et découpage en tranches</h4>
<p>L’indexation dans <code>torch</code> est basée sur 1, tout comme en R en général. Et tout comme en R, les dimensions singleton seront abandonnées - sauf si vous spécifiez<code>drop = FALSE</code> :</p>
<pre class="r"><code>t1

t1[ , 1, , ]
t1[ , 1, , , drop = FALSE]</code></pre>
<p>Les plages de valeurs (“tranches”) se peuvent accéder en utilisant le point-virgule :</p>
<pre class="r"><code>t1[1, 1, 1:2, ]
t1[1, 1, 1:2, , drop = FALSE]</code></pre>
<p>Un raccourci qui n’existe pas en R (où la même syntaxe a une sémantique différente), l’indice -1 est utilisé pour faire référence au dernier élément d’une dimension singleton :</p>
<pre class="r"><code>t2 &lt;- torch_tensor(1:17)
t2[-1] </code></pre>
</div>
<div id="section-diffusion-broadcasting" class="section level4">
<h4>Diffusion (“broadcasting”)</h4>
<p>Dans <code>torch</code>, les tenseurs peuvent être diffusés. Le principe est le même que lorsque, en R, on ajoute un scalaire à chaque élément d’un vecteur. Mais ça va plus loin que cela. Nous n’avons pas le temps d’expliquer les règles en détail, mais nous montrons quelques exemples. (Ainsi qu’un énoncé bref des règles, pour que vous puissiez y revenir plus tard.)</p>
<p>Ici, nous “ajoutons” une matrice et un vecteur, ce qui fait que le vecteur est ajouté à chaque ligne de la matrice. Ceci n’est possible que parce que <code>t2</code> a une dimension singleton à l’avant.</p>
<pre class="r"><code>t1 &lt;- torch_randn(c(3,5))
t2 &lt;- torch_randn(c(1,5))

t1$add(t2)</code></pre>
<p>L’ exemple suivant est similaire, mais il implique une opération supplémentaire du côté de <code>torch</code> : <code>t2</code> est d’abord virtuellement étendu à la taille 1x5 (une dimension singleton est ajoutée devant). Ensuite, les choses se passent comme ci-dessus.</p>
<pre class="r"><code>t1 &lt;- torch_randn(c(3,5))
t2 &lt;- torch_randn(c(5))

t1$add(t2)</code></pre>
<p>Comme dernier exemple, nous voyons ici à la fois l’ajout virtuel d’une dimension singleton (à <code>t1</code>) et la “réutilisabilité” des dimensions singleton montrée avant. Cette dernière idée est utilisée deux fois, pour <code>t1</code> ainsi que pour <code>t2</code>.</p>
</div>
<div id="section-annexe-règles-de-diffusion" class="section level4">
<h4>Annexe : Règles de diffusion</h4>
<pre><code># 1 Nous alignons les formes du tableau, en commençant par la droite.
  
  # Exemple

  # t1, forme :     8  1  6  1
  # t2, forme :        7  1  5
  

# 2 En regardant à partir de la droite, les tailles le long des axes alignés doivent soit correspondre exactement, soit l&#39;une d&#39;entre elles doit être égale à 1.
# Dans ce dernier cas, le tenseur à une dimension est diffusé vers le plus long.

  # Exemple : Cela se produit dans la dernière (pour t1) ainsi que dans l&#39;avant-dernière dimension (pour t2).

  # t1, forme :     8  1  6  5
  # t2, forme :        7  6  5


# 3 Si à gauche, l&#39;un des tableaux a un axe supplémentaire (ou plus d&#39;un),
l&#39;autre est virtuellement étendu pour avoir une taille de 1 à cet endroit.


#  Ensuite, la diffusion se fera comme indiqué dans (2).

  # Exemple : Ça se passe dans la dimension la plus à gauche de t1. D&#39;abord,   il y a une expansion virtuelle

  # t1, forme :     8  1  6  1
  # t2, forme :     1  7  1  5

  # et ensuite, la diffusion se produit :
  
  # t1, forme :     8  1  6  1
  # t2, forme :     8  7  1  5</code></pre>
</div>
<div id="section-exercice-tenseurs" class="section level4">
<h4>Exercice : Tenseurs</h4>
<p>Dans les exercices suivants, essayez de traduire le code R en opérations équivalentes <code>torch</code>.</p>
<ol style="list-style-type: decimal">
<li>Créez deux tenseurs représentant respectivement une matrice et un vecteur :</li>
</ol>
<div class="tutorial-exercise" data-label="tensors1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># une matrice
m1 &lt;- matrix(1:32, ncol = 8, byrow = TRUE)

# en réalité, un vecteur
m2 &lt;- matrix(1:8, ncol = 1)

m1</code></pre>
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    2    3    4    5    6    7    8
[2,]    9   10   11   12   13   14   15   16
[3,]   17   18   19   20   21   22   23   24
[4,]   25   26   27   28   29   30   31   32</code></pre>
<pre class="text"><code>m2</code></pre>
<pre><code>     [,1]
[1,]    1
[2,]    2
[3,]    3
[4,]    4
[5,]    5
[6,]    6
[7,]    7
[8,]    8</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors1-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1 &lt;- torch_tensor(matrix(1:32, ncol = 8, byrow = TRUE))
t2 &lt;- torch_tensor(1:8)

t1
t2</code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Multipliez les matrices, faites la somme de tous les éléments et prenez la racine carrée :</li>
</ol>
<div class="tutorial-exercise" data-label="tensors2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>(m1 %*% m2)^2 %&gt;% sum() %&gt;% sqrt()</code></pre>
<pre><code>[1] 1425.729</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors2-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1$matmul(t2)$square()$sum()$to(dtype = torch_float())$sqrt()</code></pre>
</div>
<p>[Notez comment nous avons besoin de convertir en flottant afin d’être en mesure d’appeler <code>torch_sqrt()</code>.]</p>
<ol start="3" style="list-style-type: decimal">
<li>Multiplier chaque ligne de <code>m1</code> par le vecteur <code>m2</code> (par éléments) :</li>
</ol>
<div class="tutorial-exercise" data-label="tensors3" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>m1 * rbind(t(m2), t(m2), t(m2), t(m2))</code></pre>
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    4    9   16   25   36   49   64
[2,]    9   20   33   48   65   84  105  128
[3,]   17   36   57   80  105  132  161  192
[4,]   25   52   81  112  145  180  217  256</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors3-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1 * t2</code></pre>
</div>
<p>[Notez comment la diffusion s’occupe de la duplication pour nous. Aussi, notez comment aucune transposition n’est nécessaire, car <code>torch</code> n’a aucun concept de vecteurs de ligne vs. vecteurs de colonne.]</p>
<ol start="4" style="list-style-type: decimal">
<li>Transposez la matrice <code>m1</code>, et calculez les sommes des colonnes. (Cela devrait donner 4 valeurs).</li>
</ol>
<div class="tutorial-exercise" data-label="tensors4" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t(m1) %&gt;% apply(2, sum)</code></pre>
<pre><code>[1]  36 100 164 228</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors4-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1$t()$sum(dim = 1)</code></pre>
</div>
<p>[Notez comment l’application de la somme sur la dimension 1 (et non 2) réduit les rangées. Essayez de le voir comme ceci : Étant donné un indice dans les dimensions, en R, nous pensons “grouper par”. Dans <code>torch</code>, on pense “réduire”.]</p>
<ol start="5" style="list-style-type: decimal">
<li>Normalisez <code>m1</code> en soustrayant la moyenne et en divisant par l’écart-type.</li>
</ol>
<div class="tutorial-exercise" data-label="tensors5" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>(m1 - mean(m1)) / sd(m1)</code></pre>
<pre><code>            [,1]       [,2]       [,3]       [,4]       [,5]       [,6]
[1,] -1.65230555 -1.5457052 -1.4391048 -1.3325045 -1.2259041 -1.1193038
[2,] -0.79950269 -0.6929023 -0.5863020 -0.4797016 -0.3731013 -0.2665009
[3,]  0.05330018  0.1599005  0.2665009  0.3731013  0.4797016  0.5863020
[4,]  0.90610304  1.0127034  1.1193038  1.2259041  1.3325045  1.4391048
           [,7]        [,8]
[1,] -1.0127034 -0.90610304
[2,] -0.1599005 -0.05330018
[3,]  0.6929023  0.79950269
[4,]  1.5457052  1.65230555</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors5-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1 &lt;- t1$to(dtype = torch_float())
(t1 - t1$mean()) / t1$std()</code></pre>
</div>
<p>Tout comme <code>torch_sum()</code>, <code>torch_mean()</code> et<code>torch_std()</code> ont besoin que leur entrée soit de type float.</p>
</div>
</div>
<div id="section-différenciation-automatique-avec-autograd" class="section level3">
<h3>Différenciation automatique avec autograd</h3>
<div id="section-comment-ça-marche" class="section level4">
<h4>Comment ça marche</h4>
<p><code>torch</code> autograd fournit de la différenciation automatique pour les opérations exécutées sur les tenseurs. Pour que cela se produise, le tenseur “source” (ou “feuille”, comme <code>torch</code> l’appelle) - celui par rapport auquel nous voulons que les dérivés soient calculés - doit être créé avec <code>requires_grad = TRUE</code>. Appelons-le <code>a</code> :</p>
<pre class="r"><code>a &lt;- torch_tensor(matrix(1:4, ncol = 2, byrow = TRUE), dtype = torch_float(), requires_grad = TRUE)</code></pre>
<p>Dans cet exemple, <code>c</code>, la sortie, dépend de <code>a</code> via <code>b</code> :</p>
<pre class="r"><code>b &lt;- a$mul(2)
c &lt;- b$sum()</code></pre>
<p>Jusqu’à présent, aucun dérivé n’a encore été calculé. Mais <code>torch</code> sait ce qu’il faut faire si nous le lui demandons. Plus précisément, il connaît les opérations concrètes pour lesquelles il va falloir les dérivées :</p>
<pre class="r"><code>c$grad_fn
b$grad_fn</code></pre>
<p>Pour les faire calculer, appelez <code>$backward()</code>sur le tenseur de sortie :</p>
<pre class="r"><code>c$backward()</code></pre>
<p>Maintenant, le gradient de <code>c</code> par rapport à <code>a</code> peut être trouvé dans le champ <code>$grad</code> de <code>a</code>.</p>
<pre class="r"><code>a$grad</code></pre>
<p>Lorsque nous mettons à jour un tenseur “feuille”, par exemple dans l’optimisation, nous ne voulons pas que <code>torch</code> enregistre cette opération pour le calcul ultérieur des dérivés. Dans ces cas, nous devons lui dire d’exempter l’opération en question du processus :</p>
<pre class="r"><code>with_no_grad( {
  a$sub_(0.1 * a$grad)
})

a</code></pre>
</div>
<div id="section-minimiser-une-fonction-avec-autograd" class="section level4">
<h4>Minimiser une fonction avec autograd</h4>
<p>Nous pouvons utiliser autograd pour minimiser une fonction. Nous définissons un paramètre pour contenir <span class="math inline">\(\mathbf{x}\)</span>. Ensuite, dans une boucle, nous évaluons la fonction à la valeur courante de <span class="math inline">\(\mathbf{x}\)</span>, calculons le gradient, et soustrayons une fraction du gradient de <span class="math inline">\(\mathbf{x}\)</span>.</p>
<pre class="r"><code># fonction à minimiser
f &lt;- function(x) x^2 - 7

# on démarre à x = 11
param &lt;- torch_tensor(11, requires_grad = TRUE)

# taux d&#39;apprentissage  : fraction du gradient à soustraire
lr &lt;- 0.1

for (i in 1:num_iterations) {
  
  # appeler la fonction sur la valeur du paramètre actuel

  # calculer le gradient de la valeur par rapport au paramètre

  # mettre à jour le paramètre

}</code></pre>
<p>Dans l’exercice, il vous est demandé de compléter les pièces manquantes.</p>
</div>
<div id="section-exercice-minimisation-de-fonction" class="section level4">
<h4>Exercice : Minimisation de fonction</h4>
<p>Remplissez les lignes marquées “à compléter”. Une fois le code exécuté, expérimentez avec le taux d’apprentissage et comparez les résultats. Quel est un bon taux d’apprentissage pour ce problème ?</p>
<div class="tutorial-exercise" data-label="autograd" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># fonction à minimiser
f &lt;- function(x) x^2 - 7

# on démarre à x = 11
param &lt;- torch_tensor(11, requires_grad = TRUE)

# taux d&#39;apprentissage  : fraction du gradient à soustraire
lr &lt;- 0.1

for (i in 1:10) {
  
  cat(&quot;Iteration : &quot;, i, &quot;\n&quot;)
  
  # appeler la fonction sur la valeur du paramètre actuel
  value &lt;- 777 # à compléter
  cat(&quot;Value is : &quot;, as.numeric(value), &quot;\n&quot;)
  
  # calculer le gradient de la valeur par rapport au paramètre
  # à compléter
  # décommentez la ligne suivante quand vous êtes prêt
  # cat(&quot;Gradient is : &quot;, as.matrix(param$grad), &quot;\n&quot;)
  
  # mettre à jour le paramètre
  # envelopper dans with_no_grad()
  with_no_grad({
    # soustraire une fraction du gradient du paramètre
    # à compléter
    
    # mettre à zéro à chaque itération (sinon, il y aurait accumulation)
    # à compléter
  })
  
  cat(&quot;After update : Param is : &quot;, as.matrix(param), &quot;\n\n&quot;)
  
  if (abs(-7 - as.numeric(value)) &lt; 0.00005) break
}</code></pre>
<pre><code>Iteration :  1 
Value is :  777 
After update : Param is :  11 

Iteration :  2 
Value is :  777 
After update : Param is :  11 

Iteration :  3 
Value is :  777 
After update : Param is :  11 

Iteration :  4 
Value is :  777 
After update : Param is :  11 

Iteration :  5 
Value is :  777 
After update : Param is :  11 

Iteration :  6 
Value is :  777 
After update : Param is :  11 

Iteration :  7 
Value is :  777 
After update : Param is :  11 

Iteration :  8 
Value is :  777 
After update : Param is :  11 

Iteration :  9 
Value is :  777 
After update : Param is :  11 

Iteration :  10 
Value is :  777 
After update : Param is :  11 </code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="autograd-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>f &lt;- function(x) x^2 - 7

param &lt;- torch_tensor(11, requires_grad = TRUE)

lr &lt;- 0.5

for (i in 1:10) {
  
  cat(&quot;Iteration : &quot;, i, &quot;\n&quot;)
  
  value &lt;- f(param)
  cat(&quot;Value is : &quot;, as.numeric(value), &quot;\n&quot;)

  value$backward()
  cat(&quot;Gradient is : &quot;, as.matrix(param$grad), &quot;\n&quot;)
  
  with_no_grad({
    param$sub_(lr * param$grad)
    param$grad$zero_()
  })
  
  cat(&quot;After update : Param is : &quot;, as.matrix(param), &quot;\n\n&quot;)
  
  if (abs(-7 - as.numeric(value)) &lt; 0.00005) break
}</code></pre>
</div>
</div>
</div>
<div id="section-modules-et-optimiseurs" class="section level3">
<h3>Modules et optimiseurs</h3>
<p>Bien que tout puisse être fait avec les tenseurs et autograd seuls, coder un grand réseau neuronal de cette manière serait une tâche assez lourde. Heureusement, ce n’est pas nécessaire. D’une part, torch fournit un ensemble riche de modules de réseaux neuronaux qui cachent la logique des couches ; et d’autre part, ses optimiseurs encapsulent des algorithmes d’optimisation connus pour leur efficacité dans l’apprentissage profond.</p>
<div id="section-modules-de-réseaux-neuronaux" class="section level4">
<h4>Modules de réseaux neuronaux</h4>
<p><code>torch</code> utilise le terme module pour les couches individuelles (par exemple, couche , couche convolutive …) ainsi que pour les modèles, c’est-à-dire les réseaux neuronaux. La logique ici est que les modules sont composables ; un modèle/module n’est rien d’autre qu’une composition de modules plus petits, qui peuvent à nouveau contenir des modules encore plus petits, etc.</p>
<div id="section-module-linéaire" class="section level5">
<h5>Module linéaire</h5>
<p>Voici une transformation affine, codée manuellement :</p>
<pre class="r"><code># données d&#39;entrée
x &lt;- torch_randn(c(7,2))

# poids
w &lt;- torch_tensor(c(0.1, 0.1), requires_grad = TRUE)
# biais
b &lt;- torch_tensor(0.5, requires_grad = TRUE)
  
x$matmul(w) + b  </code></pre>
<p>Nous pouvons réaliser la même chose en utilisant un module linéaire :</p>
<pre class="r"><code>l &lt;- nn_linear(in_features = 2, out_features = 1)
l(x)</code></pre>
<p>Le résultat est différent de celui ci-dessus, parce que là nous avons défini le poids nous-mêmes. Par défaut, <code>torch</code> va initialiser les poids uniformément, avec des valeurs comprises entre<code>[-sqrt(num_features), sqrt(num_features)]</code>.</p>
<pre class="r"><code>l$weight </code></pre>
<p>Juste pour prouver le point, nous pouvons initialiser manuellement les poids du module:</p>
<pre class="r"><code>nn_init_constant_(l$weight, 0.1)
nn_init_constant_(l$bias, 0.5)

l(x)</code></pre>
<p>Avec les modules, nous bénéficions gratuitement de la différenciation automatique. Supposons que l’on veuille minimiser la somme des sorties.</p>
<pre class="r"><code>loss &lt;- l(x)$sum() 
loss$grad_fn</code></pre>
<p>Nous devrons toujours appeler <code>$backward()</code>pour voir les dérivés en effet calculés. Ici, elles sont encore indéfinies :</p>
<pre class="r"><code>l$weight$grad
l$bias$grad</code></pre>
<p>Appelant <code>$backward()</code> …</p>
<pre class="r"><code>loss$backward()

l$weight$grad
l$bias$grad</code></pre>
</div>
<div id="section-exemples-dautres-modules" class="section level5">
<h5>Exemples d’autres modules</h5>
<p>Il existe de nombreux autres modules. Voici un tenseur imitant une image RVB 32x32:</p>
<pre class="r"><code>img &lt;- torch_rand(c(1, 3, 32, 32))</code></pre>
<p>Maintenant, <code>nn_conv2d()</code> est utilisé pour créer une couche convolutive, et son filtre 3x3 est appliqué à l’image :</p>
<pre class="r"><code>conv &lt;- nn_conv2d(in_channels = 3, out_channels = 1, kernel_size = 3, padding = 1)

conv(img)</code></pre>
<p>Un autre module couramment utilisé dans le traitement des images est <code>nn_max_pool2d()</code> pour la réduction de la taille spatiale :</p>
<pre class="r"><code>pool &lt;- nn_max_pool2d(kernel_size = 2)
conv(img) %&gt;% pool()</code></pre>
<p>Dans la troisième section de ce tutoriel, nous allons rencontrer des modules communs dans le traitement des séries temporelles.</p>
</div>
<div id="section-composer-des-modules" class="section level5">
<h5>Composer des modules</h5>
<p>Pour construire un " modèle " à partir de " couches " telles que celles que nous avons montrées ci-dessus, nous pouvons utiliser <code>nn_sequential()</code>.</p>
<p>Voici un modèle composé de deux couches linéaires, avec entre elles un module ReLU (<code>nn_relu()</code>). ReLU est l’abréviation de “Rectified Linear Unit” (unité linéaire rectifiée) ; son but est d’introduire une certaine non-linéarité dans ce modèle :</p>
<pre class="r"><code>model &lt;- nn_sequential(
  nn_linear(2, 16),
  nn_relu(),
  nn_linear(16, 1)
)

model$parameters

model(x)</code></pre>
<p>Vous pouvez également définir vos propres modules. Nous en verrons des exemples dans la deuxième partie.</p>
</div>
</div>
<div id="section-optimiseurs" class="section level4">
<h4>Optimiseurs</h4>
<p>Parmi les optimiseurs les plus couramment utilisés dans l’apprentissage profond figurent Adam (<code>optim_adam()</code>), RMSProp (<code>optim_rmsprop()</code>), and Stochastic Gradient Descent (SGD ; <code>optim_sgd()</code>).</p>
<p>Ici, nous utilisons <code>optim_adam()</code> pour démontrer leur utilisation.</p>
<pre class="r"><code># quelques données fictives
x &lt;- torch_tensor(c(1.2, 0.8, 0.7))
y &lt;- torch_tensor(1)</code></pre>
<p>Lorsqu’un optimiseur est créé, il faut lui indiquer ce qu’il doit optimiser, à savoir les paramètres du modèle. La plupart des optimiseurs ont également besoin de recevoir le taux d’apprentissage.</p>
<pre class="r"><code>model &lt;- nn_sequential(
  nn_linear(3, 8),
  nn_relu(),
  nn_linear(8, 1)
)

optimizer &lt;- optim_adam(model$parameters, lr = 0.01)</code></pre>
<p>Nous obtenons une prédiction :</p>
<pre class="r"><code>prediction &lt;- model(x)
prediction</code></pre>
<p>Nous utilisons ensuite l’une des fonctions de perte intégrées en <code>torch</code> pour calculer la perte (ici, l’erreur quadratique moyenne) :</p>
<pre class="r"><code>loss &lt;- nnf_mse_loss(prediction, y)
loss</code></pre>
<p>Nous appelons <code>$backward()</code> sur la perte pour que les gradients soient calculés :</p>
<pre class="r"><code>loss$backward()</code></pre>
<p>Maintenant, les gradients sont connus, mais aucune modification n’a encore été apportée aux paramètres du modèle.</p>
<pre class="r"><code>model$parameters</code></pre>
<p>L’appel de <code>$step()</code> sur l’optimiseur effectuera ces changements.</p>
<pre class="r"><code>optimizer$step()</code></pre>
<pre class="r"><code>model$parameters</code></pre>
<p>Lors de la formation effective d’un réseau, nous appelons l’optimiseur dans une boucle. Nous en montrons un exemple ci-dessous.</p>
<p>Tout d’abord, nous créons les données d’entraînement.</p>
<pre class="r"><code># dimensionnalité de l&#39;entrée (nombre de caractéristiques d&#39;entrée)
d_in &lt;- 3
# dimensionnalité de la sortie (nombre de caractéristiques prédites)
d_out &lt;- 1
# nombre d&#39;observations dans l&#39;ensemble d&#39;entraînement
n &lt;- 100

# créer des données aléatoires
x &lt;- torch_randn(n, d_in)
y &lt;- x[, 1, NULL] * 0.2 - x[, 2, NULL] * 1.3 - x[, 3, NULL] * 0.5 + torch_randn(n, 1)</code></pre>
<p>Ensuite, nous définissons le réseau.</p>
<pre class="r"><code># dimensionnalité de la couche cachée
d_hidden &lt;- 32

model &lt;- nn_sequential(
  nn_linear(d_in, d_hidden),
  nn_relu(),
  nn_linear(d_hidden, d_out)
)</code></pre>
<p>On crée l’optimiseur:</p>
<pre class="r"><code>learning_rate &lt;- 0.08

# L&#39;optimiseur applique les mises à jour du gradient pour nous
optimizer &lt;- optim_adam(model$parameters, lr = learning_rate)</code></pre>
<p>Et nous sommes prêts pour la boucle d’entraînement. Dans une boucle, nous</p>
<ul>
<li><p>obtenons les prédictions du modèle ;</p></li>
<li><p>calculons la perte ; et</p></li>
<li><p>propageons la perte à travers le réseau et mettons à jour les paramètres.</p></li>
</ul>
<p>Notez que lors d’une optimisation en boucle, nous devons remettre à zéro les gradients à chaque itération.</p>
<pre class="r"><code>for (t in 1:200) {
  
  ### -------- Passe avant -------- 
  y_pred &lt;- model(x)
  
  ### -------- calculer la perte -------- 
  # erreur quadratique moyenne
  loss &lt;- nnf_mse_loss(y_pred, y, reduction = &quot;sum&quot;)
  if (t %% 10 == 0)
    cat(&quot;Epoch : &quot;, t, &quot;   Loss : &quot;, loss$item(), &quot;\n&quot;)
  
  ### -------- Rétropropagation -------- 
  
  # faut remettre à zéro les gradients avant le passage en arrière, car ils s&#39;accumuleraient autrement.
  optimizer$zero_grad()
  
  # calculer les gradients 
  loss$backward()
  
  # mettre à jour les poids 
  optimizer$step()
}</code></pre>
<p>Bien qu’elle soit beaucoup plus pratique que de travailler uniquement avec des tenseurs, cette méthode d’entraînement d’un réseau neuronal reste de très bas niveau et nécessite une attention particulière pour les particularités (comme la mise à zéro des gradients). Dans la deuxième partie, nous verrons comment former des réseaux neuronaux de manière beaucoup plus confortable avec <code>luz</code>.</p>
</div>
<div id="section-exercice-formation-dun-réseau-de-neurones" class="section level4">
<h4>Exercice : Formation d’un réseau de neurones</h4>
<p>Ci-dessous, vous trouverez le code de bout en bout pour former un réseau neuronal. Essayez de l’expérimenter un peu :</p>
<p>Si vous modifiez le taux d’apprentissage, que se passe-t-il ?</p>
<p>Essayez d’autres optimiseurs, tels que <code>optim_sgd()</code>. Comment cela affecte-t-il la formation ?</p>
<div class="tutorial-exercise" data-label="modules" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># dimensionnalité de l&#39;entrée (nombre de caractéristiques d&#39;entrée)
d_in &lt;- 3
# dimensionnalité de la sortie (nombre de caractéristiques prédites)
d_out &lt;- 1
# nombre d&#39;observations dans l&#39;ensemble d&#39;entraînement
n &lt;- 100

# créer des données aléatoires
x &lt;- torch_randn(n, d_in)
y &lt;- x[, 1, NULL] * 0.2 - x[, 2, NULL] * 1.3 - x[, 3, NULL] * 0.5 + torch_randn(n, 1)

# dimensionnalité de la couche cachée
d_hidden &lt;- 32

model &lt;- nn_sequential(
  nn_linear(d_in, d_hidden),
  nn_relu(),
  nn_linear(d_hidden, d_out)
)

learning_rate &lt;- 0.08

# L&#39;optimiseur applique les mises à jour du gradient pour nous
optimizer &lt;- optim_adam(model$parameters, lr = learning_rate)

for (t in 1:200) {
  
  ### -------- Passe avant -------- 
  y_pred &lt;- model(x)
  
  ### -------- calculer la perte -------- 
  # erreur quadratique moyenne
  loss &lt;- nnf_mse_loss(y_pred, y, reduction = &quot;sum&quot;)
  if (t %% 10 == 0)
    cat(&quot;Epoch : &quot;, t, &quot;   Loss : &quot;, loss$item(), &quot;\n&quot;)
  
  ### -------- Rétropropagation -------- 
  
  # faut remettre à zéro les gradients avant le passage en arrière, car ils s&#39;accumuleraient autrement.
  optimizer$zero_grad()
  
  # calculer les gradients 
  loss$backward()
  
  # mettre à jour les poids 
  optimizer$step()
}</code></pre>
<pre><code>Epoch :  10    Loss :  111.8518 
Epoch :  20    Loss :  100.0569 
Epoch :  30    Loss :  89.02506 
Epoch :  40    Loss :  77.87939 
Epoch :  50    Loss :  68.5024 
Epoch :  60    Loss :  60.12441 
Epoch :  70    Loss :  54.11732 
Epoch :  80    Loss :  50.70421 
Epoch :  90    Loss :  47.39006 
Epoch :  100    Loss :  44.52914 
Epoch :  110    Loss :  41.70057 
Epoch :  120    Loss :  40.00521 
Epoch :  130    Loss :  38.26446 
Epoch :  140    Loss :  36.11102 
Epoch :  150    Loss :  34.75252 
Epoch :  160    Loss :  32.20155 
Epoch :  170    Loss :  35.44614 
Epoch :  180    Loss :  32.34827 
Epoch :  190    Loss :  30.15497 
Epoch :  200    Loss :  28.59554 </code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
</div>
</div>
<div id="section-formation-de-réseaux-neuronaux-avec-luz" class="section level2">
<h2>Formation de réseaux neuronaux avec <code>luz</code></h2>
<p><code>luz</code> est une API de haut niveau pour <code>torch</code> qui vous permet de former des réseaux de neurones dans un style déclaratif.</p>
<p>Avec <code>luz</code>, le flux global ressemble beaucoup à celui de Keras :</p>
<ol style="list-style-type: decimal">
<li><p>Vous définissez un modèle.</p></li>
<li><p>Vous utilisez <code>setup()</code>pour le configurer avec une fonction de perte, un optimiseur et un ensemble de métriques.</p></li>
<li><p>Vous l’entraînez en utilisant<code>fit(),</code> en passant les données d’entraînement et (facultativement) de validation, ainsi que le nombre d’époques à entraîner et un ensemble de rappels (tous deux facultatifs).</p></li>
</ol>
<div id="section-exemple-de-bout-en-bout-mnist" class="section level3">
<h3>Exemple de bout en bout : MNIST</h3>
<p>Pour présenter <code>luz</code>, nous allons faire le “bonjour au monde” de l’apprentissage profond : la classification de chiffres sur le (in-)célèbre jeu de données MNIST. MNIST est disponible comme partie du paquet <code>torchvision</code>.</p>
<div id="section-données" class="section level4">
<h4>Données</h4>
<p>Dans <code>torch</code>, les données sont fournies à un réseau en utilisant des <code>dataset</code>s et des <code>dataloaders</code>. Leurs responsabilités respectives sont les suivantes :</p>
<ul>
<li><p><code>dataset</code> : Renvoie un seul élément de formation, de validation ou de test. Dans l’apprentissage supervisé, il s’agit d’une liste d’entrée et de cible. Optionnellement, s’occupe de tout prétraitement requis.</p></li>
<li><p><code>dataloader</code> : Introduit les données dans le modèle. Normalement, cela se fait par lots de taille configurable. En option, un <code>dataloader</code> peut mélanger les données et organiser la parallélisation sur un sous-ensemble de processeurs disponibles.</p></li>
</ul>
<p><code>torchvision</code> est livré avec quelques jeux de données d’images, qui peuvent être demandés via <code>xxx_dataset()</code>. Ils seront téléchargés et préparés la première fois qu’ils sont instanciés (à moins que les données existent déjà dans l’emplacement spécifié).</p>
<p>Comme nous n’avons pas vraiment besoin de l’ensemble complet de données MNIST pour cette démonstration, nous ne préparons que la partie test (comme indiquée par la ligne <code>train = FALSE</code> ci-dessous). Nous la diviserons manuellement en parties formation et validation dans une minute.</p>
<p>Dans le constructeur du <code>dataset</code>, l’argument <code>transform =</code> sert à dire à torch comment les images doivent être prétraitées.</p>
<pre class="r"><code>dir &lt;- &quot;~/Downloads/mnist&quot; 

ds &lt;- mnist_dataset(
  dir,
  train = FALSE,
  transform = function(x) {
    x %&gt;% transform_to_tensor() 
  }
)</code></pre>
<p><code>ds</code> a maintenant 10 000 paires image-étiquette :</p>
<pre class="r"><code>length(ds)</code></pre>
<p>Nous pouvons utiliser l’indexation pour les inspecter :</p>
<pre class="r"><code>ds[1]</code></pre>
<p>En utilisant <code>dataset_subset()</code>, nous divisons ces 10 000 paires en ensembles de formation et de validation :</p>
<pre class="r"><code>train_id &lt;- sample.int(length(ds), size = 0.7*length(ds))
train_ds &lt;- dataset_subset(ds, indices = train_id)
valid_ds &lt;- dataset_subset(ds, indices = which( !seq_along(ds) %in% train_id))</code></pre>
<p>Ensuite, nous créons les <code>dataloader</code>s respectifs.</p>
<pre class="r"><code>train_dl &lt;- dataloader(train_ds, batch_size = 128, shuffle = TRUE)
valid_dl &lt;- dataloader(valid_ds, batch_size = 128, shuffle = FALSE)</code></pre>
<p>Avec <code>dataloader</code>s, <code>length()</code> indique le nombre des <em>lots</em> :</p>
<pre class="r"><code>length(train_dl)
length(valid_dl)</code></pre>
</div>
<div id="section-modèle" class="section level4">
<h4>Modèle</h4>
<p>Le modèle est un réseau neuronal convolutif qui filtre et réduit successivement ses entrées, pour arriver finalement à une prédiction de classe. Il y a dix types de chiffres (0-9), et pour chaque chiffre, il produira un score pour chacune des dix étiquettes possibles.</p>
<p>Dans la définition du modèle, notez le paramètre num_classes. Dans cet exemple, il n’y a pas de réel besoin de paramétrer le nombre de classes avec lesquelles le modèle peut travailler ; cependant, nous aimerions montrer comment avec <code>luz</code>, vous pouvez garder la définition du modèle flexible et ne passer la configuration désirée qu’au moment de la formation.</p>
<pre class="r"><code>net &lt;- nn_module(
  &quot;Net&quot;,
  initialize = function(num_classes) {
    self$conv1 &lt;- nn_conv2d(1, 32, 3, 1)
    self$conv2 &lt;- nn_conv2d(32, 64, 3, 1)
    self$dropout1 &lt;- nn_dropout2d(0.25)
    self$dropout2 &lt;- nn_dropout2d(0.5)
    self$fc1 &lt;- nn_linear(9216, 128)
    self$fc2 &lt;- nn_linear(128, num_classes)
  },
  forward = function(x) {
    x %&gt;% 
      self$conv1() %&gt;% 
      nnf_relu() %&gt;% 
      self$conv2() %&gt;% 
      nnf_relu() %&gt;% 
      nnf_max_pool2d(2) %&gt;% 
      self$dropout1() %&gt;% 
      torch_flatten(start_dim = 2) %&gt;% 
      self$fc1() %&gt;% 
      nnf_relu() %&gt;% 
      self$dropout2() %&gt;% 
      self$fc2()
  }
)</code></pre>
</div>
<div id="section-formation" class="section level4">
<h4>Formation</h4>
<p>Maintenant que nous avons la définition du modèle, tout ce qui nous sépare de l’observation de son entraînement sont deux appels à <code>luz</code> : <code>setup()</code> et <code>fit()</code>.</p>
<ul>
<li><p>En utilisant <code>setup()</code>, nous configurons la fonction de perte et l’optimiseur à utiliser ; de plus, nous pouvons demander le calcul d’un ensemble de métriques.</p></li>
<li><p>En appelant fit, nous démarrons le processus d’apprentissage. Le premier argument est toujours le <code>dataloader</code> contenant les données d’entraînement ; les autres arguments sont facultatifs et incluent le nombre d’époques, et éventuellement un autre <code>dataloader</code> pour la validation.</p></li>
</ul>
<p>Alors que <code>setup()</code> et <code>fit()</code> sont “obligatoires”, <code>set_hparams()</code>, située entre les deux, ne l’est pas. Cette fonction peut être utilisée pour définir les variables utilisées dans le modèle ; ici, nous passons la valeur souhaitée pour le paramètre <code>num_classes</code> mentionné ci-dessus.</p>
<pre class="r"><code>fitted &lt;- net %&gt;%
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_adam,
    metrics = list(
      luz_metric_accuracy()
    )
  ) %&gt;%
  set_hparams(num_classes = 10) %&gt;%
  fit(train_dl, epochs = 3, valid_data = valid_dl, verbose = TRUE)</code></pre>
</div>
<div id="section-prédictions" class="section level4">
<h4>Prédictions</h4>
<p>Les prédictions peuvent être obtenues en utilisant <code>predict()</code>, en passant le modèle entrâiné et le <code>dataloader</code> pour lequel nous voulons que les prédictions soient calculées.</p>
<p>Ces prédictions ne sont rien d’autre que la sortie de la couche finale du modèle :</p>
<pre class="r"><code>preds &lt;- predict(fitted, valid_dl)
preds[1:10, ]</code></pre>
<p>La classe la mieux ajustée est celle pour laquelle la valeur du tenseur (le score) est la plus élevée. Si, à la place de scores non-normalisés, nous souhaitons des probabilités, nous pouvons faire passer les scores bruts par un <code>softmax</code> :</p>
<pre class="r"><code>(nnf_softmax(preds[1:10, ], dim = 2))$to(device = &quot;cpu&quot;) %&gt;% as.matrix() %&gt;% round(2)</code></pre>
</div>
<div id="section-sauvegarde-et-chargement-de-modèles" class="section level4">
<h4>Sauvegarde et chargement de modèles</h4>
<p>Pour compléter l’essentiel de <code>luz</code>, voici ses fonctions d’aide pour sauvegarder et charger les modèles :</p>
<pre class="r"><code>luz_save(fitted, &quot;mnist-cnn.pt&quot;)
copy &lt;- luz_load(&quot;mnist-cnn.pt&quot;)</code></pre>
</div>
</div>
<div id="section-exercice-rappels" class="section level3">
<h3>Exercice : Rappels</h3>
<p>Les rappels offrent un moyen extrêmement flexible de personnaliser la routine d’entraînement. <code>luz</code> lui-même utilise des rappels en interne, par exemple pour calculer les métriques ou pour afficher la progression de l’entraînement.</p>
<p>Voici une rappel simple qui devient active à deux catégories de “temps” spécifiées :</p>
<ol style="list-style-type: decimal">
<li><p>Lorsque l’entraînement est terminé pour un seul lot (<code>on_train_batch_end()</code>).</p></li>
<li><p>Quand l’entraînement a terminé une époque complète (<code>on_epoch_end()</code>).</p></li>
</ol>
<pre class="r"><code>print_callback &lt;- luz_callback(
  
  name = &quot;print_callback&quot;,
  
  initialize = function(message) {
    self$message &lt;- message
  },
  
  on_train_batch_end = function() {
    cat(&quot;Iteration &quot;, ctx$iter, &quot;\n&quot;)
  },
  
  on_epoch_end = function() {
    cat(self$message, &quot;\n&quot;)
  }
)</code></pre>
<p>Les rappels sont passés à <code>luz</code> dans l’appel <code>fit()</code> :</p>
<pre class="r"><code>fitted &lt;- net %&gt;%
  setup(...) %&gt;%
  fit(..., callbacks = list(
    print_callback(message = &quot;Fini !&quot;)
  ))</code></pre>
<p>Via une référence de contexte (<code>ctx</code>), les rappels ont accès à un grand nombre d’objets internes au modèle et dépendants du processus, tels que le modèle lui-même, une liste d’optimiseurs utilisés, l’époque actuelle, et plus encore.</p>
<p>Pour cet exercice, implémentez un rappel qui, à la fin de chaque époque, dit “Done with epoch &lt;n&gt;”, et insérez-le dans la routine de formation.</p>
<div class="tutorial-exercise" data-label="custom-callback" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>which_epoch_callback &lt;- luz_callback(
  
  name = &quot;which_epoch_callback&quot;,
  
  # TBD
  
  
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="custom-callback-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>which_epoch_callback &lt;- luz_callback(
  
  name = &quot;which_epoch_callback&quot;,
  
  on_epoch_end = function() {
    cat(&quot;Terminé avec l&#39;époch :&quot;, ctx$epoch, &quot;\n&quot;)
  }
)</code></pre>
</div>
</div>
<div id="section-exercise-créer-sa-propre-métrique" class="section level3">
<h3>Exercise : Créer sa propre métrique</h3>
<p>Bien que <code>luz</code> fournisse un grand nombre de métriques, vous pouvez facilement implémenter les vôtres si nécessaire. Les objets métriques conservent des agrégats courants de l’indicateur en question. À chaque époque, les agrégats sont réinitialisés à leur valeur de départ (zéro, dans la plupart des cas).</p>
<p>Une métrique <code>luz</code> est un objet R6 avec trois méthodes :</p>
<ul>
<li><p><code>initialize()</code>, utilisée pour définir les valeurs de départ de chaque variable à suivre ;</p></li>
<li><p><code>update()</code>, qui indique à <code>luz</code> comment mettre à jour ces variables à chaque étape de formation (ou de validation, respectivement) ; et</p></li>
<li><p><code>compute()</code>, utilisée pour définir l’indicateur à renvoyer.</p></li>
</ul>
<p>Ci-dessous, vous serez chargé d’implémenter vous-même la précision. Voici un aperçu de ce qu’il faut faire :</p>
<pre class="r"><code>my_accuracy &lt;- luz_metric(
  abbrev = &quot;my_acc&quot;, 
  
  initialize = function() {
    # initialiser deux champs :
    # un pour contenir le nombre de prédictions correctes
    # un pour contenir le total courant des prédictions.
    # par exemple
    # self$correct &lt;-
    # self$total &lt;-
  },
 
  update = function(preds, target) {
    # 1 : utiliser pred (argument de la fonction n° 1) pour calculer les indices de la classe la plus probable (pour le lot complet).
    # pred &lt;- 
    
    # 2 : mettre à jour self$correct : ajouter le nombre de prédictions correctes.
    # self$correct &lt;- 
    
    # 3 : mettre à jour le total courant des prédictions
    # self$total &lt;- 
  },
  
  compute = function() {
    # retourner la proportion de prédictions correctes
  }
)</code></pre>
<p>Vous pouvez substituer votre propre implémentation de la précision dans le processus de formation, en remplaçant <code>luz_metric_accuracy()</code>. Avant de faire cela, testez votre implémentation de manière autonome, en la comparant avec l’implémentation officielle :</p>
<pre class="r"><code>preds_10 &lt;- preds[1:10, ]
target_10 &lt;- valid_ds[1:10]$y

metric &lt;- luz_metric_accuracy()
metric &lt;- metric$new()
metric$update(preds_10, target_10)
metric$compute()

metric2 &lt;- my_accuracy()
metric2 &lt;- metric2$new()
metric2$update(preds_10, target_10)
metric2$compute()</code></pre>
<div class="tutorial-exercise" data-label="custom-metric" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>my_accuracy &lt;- luz_metric(
  abbrev = &quot;my_acc&quot;, 
  
  initialize = function() {
    # initialiser deux champs :
    # un pour contenir le nombre de prédictions correctes
    # un pour contenir le total courant des prédictions.
    # par exemple
    # self$correct &lt;-
    # self$total &lt;-
  },
 
  update = function(preds, target) {
    # 1 : utiliser pred (argument de la fonction n° 1) pour calculer les indices de la classe la plus probable (pour le lot complet).
    # pred &lt;- 
    
    # 2 : mettre à jour self$correct : ajouter le nombre de prédictions correctes.
    # self$correct &lt;- 
    
    # 3 : mettre à jour le total courant des prédictions
    # self$total &lt;- 
  },
  
  compute = function() {
    # retourner la proportion de prédictions correctes
  }
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="custom-metric-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>my_accuracy &lt;- luz_metric(
  abbrev = &quot;my_acc&quot;, 
  
  initialize = function() {
    self$correct &lt;- 0
    self$total &lt;- 0
  },
 
  update = function(preds, target) {
    pred &lt;- torch::torch_argmax(preds, dim = 2)
    self$correct &lt;- self$correct + 
      (pred == target)$
      to(dtype = torch::torch_float())$
      sum()$
      item()
    self$total &lt;- self$total + pred$numel()
  },
  
  compute = function() {
    self$correct/self$total
  }
)</code></pre>
</div>
</div>
</div>
<div id="section-prévision-de-séries-temporelles" class="section level2">
<h2>Prévision de séries temporelles</h2>
<p>Pour illustrer la prévision de séries temporelles avec <code>torch</code>, nous utilisons l’ensemble de données <code>vic_elec</code>, disponible via le paquet <code>tsibbledata</code>. Il fournit trois années de demande d’électricité à la demi-heure pour Victoria, Australie, augmentée par des informations de température de même résolution et un indicateur de vacances quotidien.</p>
<p>Pour un apprentissage plus rapide, nous agrégeons les données par jour. Nous jetons tout sauf la demande elle-même, en nous basant exclusivement sur la série univariée.</p>
<pre class="r"><code>vic_elec_daily &lt;- vic_elec %&gt;%
  select(Time, Demand) %&gt;%
  index_by(Date = date(Time)) %&gt;%
  summarise(
    Demand = sum(Demand) / 1e3) </code></pre>
<p>Pour avoir rapidement une idée de ce à quoi nous avons affaire, il est pratique d’utiliser <code>feasts::STL()</code>.</p>
<pre class="r"><code>cmp &lt;- vic_elec_daily %&gt;% 
  model(STL(Demand)) %&gt;% 
  components()

cmp %&gt;% autoplot()</code></pre>
<p>Avant de créer un <code>dataset</code>, un <code>dataloader</code> et un modèle, parlons rapidement de la prédiction de séries temporelles avec l’apprentissage profond en général.</p>
<div id="section-la-prévision-des-séries-chronologiques-avec-lapprentissage-profond-en-bref" class="section level3">
<h3>La prévision des séries chronologiques avec l’apprentissage profond en bref</h3>
<p>Dans un modèle linéaire, les observations individuelles sont indépendantes. Leur ordre n’a pas d’importance. Il en va de même pour les ensembles d’images (pas les pixels d’une image, cependant).</p>
<p>Mais avec les séquences, comme le langage parlé ou les mesures consécutives dans le temps, l’ordre est essentiel. Nous avons donc besoin de modèles de réseaux neuronaux qui respectent la séquentialité.</p>
<p>Traditionnellement, le type de données dont nous parlons est le domaine des réseaux neuronaux récurrents (RNN). Ils sont dits récurrents car, en plus de traiter un nouvel élément de lot à chaque pas de temps (d’entrâinement), ils conservent - et mettent à jour en permanence - un état interne. Cet état est souvent appelé l’état caché.</p>
<p>Dans cette famille de RNN, les architectures de modèle les plus établies sont l’unité récurrente à grille (GRU) et la mémoire à long terme (LSTM). La LSTM diffère de la GRU en ce qu’elle conserve un état interne supplémentaire, parfois appelé état de cellule, qui lui permet de se souvenir à plus long terme. Dans ce tutoriel, nous utilisons uniquement les GRU, mais l’adaptation du code pour les LSTM est un effort gérable.</p>
<p>Pour que les RNN puissent apprendre les dépendances temporelles, les données doivent être préparées de manière à ce que chaque élément du lot contienne des informations sur plusieurs étapes temporelles. Voyons comment cela fonctionne.</p>
</div>
<div id="section-création-dun-dataset-pour-la-prévision-de-séries-temporelles" class="section level3">
<h3>Création d’un <code>dataset</code> pour la prévision de séries temporelles</h3>
<p>Dans notre introduction à <code>luz</code>, nous avons pu utiliser un objet de jeu de données préexistant, à savoir <code>mnist_dataset()</code> fourni par <code>torchvision</code>. Maintenant, nous allons construire un jeu de données personnalisé.</p>
<div id="section-lobjet-dataset" class="section level4">
<h4>L’objet <code>dataset</code></h4>
<p>Les <code>dataset</code> sont des objets R6 qui implémentent trois méthodes : <code>initialize()</code>, <code>.getitem()</code>, et <code>.length()</code>. Ici</p>
<ul>
<li><p><code>initialize()</code>est l’endroit où les données sont stockées dans des variables d’instance (et éventuellement, prétraitées) ;</p></li>
<li><p><code>.length()</code> indique à l’appelant (un <code>dataloader</code>, en général) combien d’éléments il y a dans le <code>dataset</code>; et</p></li>
<li><p><code>.getitem()</code> définit ce qui doit être renvoyé sous la forme d’une seule paire &lt;source, cible&gt; (c’est-à-dire <code>(x,y)</code> ).The last one of these is where the “business logic” surfaces.</p></li>
</ul>
</div>
<div id="section-un-dataset-de-séries-temporelles-pour-la-prédiction-à-un-pas-davance" class="section level4">
<h4>Un <code>dataset</code> de séries temporelles pour la prédiction à un pas d’avance</h4>
<p>Pour que chaque élément du lot contienne des informations sur une séquence, <code>x</code> doit être un vecteur de mesures consécutives. Combien de mesures ? Cela dépend de ce que nous savons de la série temporelle (ainsi que de l’expérimentation).</p>
<p>Quant à <code>y</code>, il dépend du nombre de pas de temps que nous voulons prévoir à l’avance. Ici, nous commençons par un seul pas. (Nous adapterons cela pour une prédiction à plusieurs étapes plus tard).</p>
<p>Pour permettre l’expérimentation avec le nombre de pas de temps qu’on utilise à apprendre, nous rendons <code>elec_dataset()</code> configurable à cet égard (voir le paramètre <code>n_timesteps</code> passé à <code>initialize()</code>).</p>
<p>Ensuite, pour chaque élément, le <code>dataset</code> renvoie une liste de <code>(x,y)</code>, où <code>x</code> est un vecteur d’observations consécutives (commençant à l’indice actuel), et <code>y</code> est la mesure juste après :</p>
<pre class="r"><code>elec_dataset &lt;- dataset(
  name = &quot;elec_dataset&quot;,
  
  initialize = function(x, n_timesteps) {
    
    self$n_timesteps &lt;- n_timesteps
    self$x &lt;- torch_tensor((x - train_mean) / train_sd)

  },
  
  .getitem = function(i) {
    
    start &lt;- i
    end &lt;- start + self$n_timesteps - 1
    
    list(
      x = self$x[start:end],
      y = self$x[end + 1]
    )
    
  },
  
  .length = function() {
    length(self$x) - self$n_timesteps
  }
)</code></pre>
<p>Maintenant, nous créons des instances d’un tel <code>dataset</code> pour la formation et la validation. Nous devons d’abord extraire la caractéristique de la demande à partir du tsibble :</p>
<pre class="r"><code>elec_train &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) %in% c(2012, 2013)) %&gt;%
  as_tibble() %&gt;%
  select(Demand) %&gt;%
  as.matrix()

elec_valid &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) == 2014) %&gt;%
  as_tibble() %&gt;%
  select(Demand) %&gt;%
  as.matrix()</code></pre>
<p>Pour améliorer les performances de formation, nous normalisons les données. À cette fin, nous calculons la moyenne et l’écart-type de l’ensemble d’entraînement :</p>
<pre class="r"><code>train_mean &lt;- mean(elec_train)
train_sd &lt;- sd(elec_train)</code></pre>
<p>D’après l’inspection, deux semaines semblent être une période raisonnable pour tirer des enseignements :</p>
<pre class="r"><code>n_timesteps &lt;- 7 * 2

train_ds &lt;- elec_dataset(elec_train, n_timesteps)
valid_ds &lt;- elec_dataset(elec_valid, n_timesteps)

length(train_ds)</code></pre>
<p>Vérifions que le <code>dataset</code> renvoie ce que nous attendons de lui.</p>
<p><code>x</code>, à un indice arbitraire, devrait être une matrice, avec quatorze lignes et une seule colonne, où la colonne correspond à la caractéristique unique, et les lignes contiennent les mesures consécutives. <code>y</code>, d’autre part, devrait être un vecteur de longueur un.</p>
<pre class="r"><code>train_ds[1]</code></pre>
</div>
<div id="section-création-des-dataloaders-réspectifs" class="section level4">
<h4>Création des <code>dataloader</code>s réspectifs</h4>
<pre class="r"><code>batch_size &lt;- 32

train_dl &lt;- train_ds %&gt;% dataloader(batch_size = batch_size, shuffle = TRUE)

valid_dl &lt;- valid_ds %&gt;% dataloader(batch_size = batch_size)</code></pre>
<p>Bien qu’il n’y ait rien de nouveau dans les appels à <code>dataloader()</code>ici, il est intéressant de vérifier la forme des lots qu’il renvoie.</p>
<pre class="r"><code>b &lt;- dataloader_make_iter(train_dl) %&gt;% dataloader_next()
b</code></pre>
<p>Un lot de <code>xs</code> a maintenant la forme (32, 14, 1). Étant donné qu’après le regroupement, les éléments du lot se trouvent dans la dimension la plus à gauche, les étapes temporelles consécutives sont maintenant situées dans la deuxième dimension à partir de la gauche.</p>
<p>Cela s’avérera important en raison de la forme des entrées attendues par les RNN.</p>
</div>
</div>
<div id="section-modèle-1" class="section level3">
<h3>Modèle</h3>
<p>Le modèle est essentiellement une enveloppe pour un RNN, avec une couche linéaire supplémentaire qui produit une prédiction unique.</p>
<div id="section-en-savoir-plus-sur-les-gru" class="section level4">
<h4>En savoir plus sur les GRU</h4>
<p>Avant d’examiner la manière dont le modèle utilise le RNN (un GRU), examinons comment un GRU se comporte individuellement. Nous voudrons savoir</p>
<ul>
<li><p>quels arguments il attend à l’instanciation ;</p></li>
<li><p>les arguments qu’il attend lorsqu’il est appelé ; et</p></li>
<li><p>ce qu’il retourne.</p></li>
</ul>
<p>Tout d’abord, pour créer un GRU, nous devons au moins lui transmettre le nombre de caractéristiques d’entrée et le nombre d’unités dans la couche cachée. Si nos données ont des éléments de lot dans leur première dimension, nous devons également passer batch_first = TRUE. Par exemple :</p>
<pre class="r"><code>gru &lt;- nn_gru(
  input_size = 1, # nombre de caractéristiques d&#39;entrée
  hidden_size = 5, # nombre de caractéristiques cachées (et de sortie !)
  batch_first = TRUE 
)</code></pre>
<p>Deuxièmement, le format d’entrée attendu (à condition que nous ayons créé le module “batch first”, comme nous l’avons fait ci-dessus) est : <code>(batch_size, num_timesteps, num_features)</code>.</p>
<p>Voici quelques données aléatoires qui répondent aux exigences :</p>
<pre class="r"><code># lot de 4, avec 8 pas de temps chacun et une seule caractéristique
input &lt;- torch_randn(c(4, 8, 1))</code></pre>
<p>Enfin, le module GRU retourne une liste de deux choses :</p>
<ul>
<li><p>la sortie, de forme (<code>batch_size, num_timesteps, num_hidden</code>) . (Encore une fois, en présupposant “batch-first”).</p></li>
<li><p>l’état caché final pour le dernier pas de temps seulement, de la forme (<code>1, batch_size, num_hidden</code>).</p></li>
</ul>
<p>Pour un GRU (par opposition à un LSTM), il n’y a pas de différence entre l’état caché et l’état de sortie quand il s’agit du dernier pas de temps, donc le deuxième tenseur dans la liste ci-dessus ne fournit aucune information supplémentaire.</p>
<pre class="r"><code>gru(input)</code></pre>
</div>
<div id="section-module-de-prédiction-complet" class="section level4">
<h4>Module de prédiction complet</h4>
<p>Le modèle prend la sortie du dernier pas de temps et la transmet à la couche de sortie linéaire, ce qui donne une seule valeur prédite.</p>
<pre class="r"><code>model &lt;- nn_module(
  
  initialize = function(input_size, hidden_size) {

    self$rnn &lt;- nn_gru(
        input_size = input_size,
        hidden_size = hidden_size,
        batch_first = TRUE
      )
    
    self$output &lt;- nn_linear(hidden_size, 1)
    
  },
  
  forward = function(x) {
    
    # liste de [output, hidden]
    # nous ne sommes intéressés que par le dernier pas de temps, nous pouvons donc utiliser directement [[2]].
    # mais nous voulons supprimer la dimension singleton inutile sur la gauche.
    x &lt;- self$rnn(x)[[2]]$squeeze(1)

    x %&gt;% self$output() 
  }
  
)</code></pre>
</div>
</div>
<div id="section-formation-1" class="section level3">
<h3>Formation</h3>
<pre class="r"><code>fitted &lt;- model %&gt;%
  setup(
    loss = nn_mse_loss(),
    optimizer = optim_adam,
    metrics = list(
     luz_metric_mse()
    )
  ) %&gt;%
  set_hparams(input_size = 1, hidden_size = 64) %&gt;%
  fit(train_dl, epochs = 20, valid_data = valid_dl, verbose = TRUE)</code></pre>
</div>
<div id="section-prédictions-en-période-de-test" class="section level3">
<h3>Prédictions en période de test</h3>
<p>Pour les tests et les graphiques, utilisons les quatre premiers mois de l’ensemble de validation. (En raccourcissant la fenêtre temporelle, on obtiendra un tracé plus utile).</p>
<pre class="r"><code>vic_elec_test &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) %in% c(2014), month(Date) %in% 1:4) 

elec_test &lt;- vic_elec_test %&gt;%
  as_tibble() %&gt;%
  select(Demand) %&gt;%
  as.matrix()

test_ds &lt;- elec_dataset(elec_test, n_timesteps)

test_dl &lt;- test_ds %&gt;% dataloader(batch_size = batch_size)</code></pre>
<p>En utilisant <code>luz</code> pour obtenir les prédictions :</p>
<pre class="r"><code>preds &lt;- predict(fitted, test_dl)
preds &lt;- as.numeric(preds)</code></pre>
<p>On peut les comparer aux cibles :</p>
<pre class="r"><code>preds &lt;- c(rep(NA, n_timesteps), preds)

preds_ts &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) %in% c(2014), month(Date) %in% 1:4) %&gt;%
  add_column(forecast = preds * train_sd + train_mean) %&gt;%
  pivot_longer(-Date) %&gt;%
  update_tsibble(key = name)

preds_ts %&gt;%
  autoplot() +
  scale_colour_manual(values = c(&quot;#08c5d1&quot;, &quot;#00353f&quot;)) +
  theme_minimal()</code></pre>
</div>
<div id="section-exercice-extension-du-modèle-à-la-prévision-à-plusieurs-étapes" class="section level3">
<h3>Exercice : Extension du modèle à la prévision à plusieurs étapes</h3>
<p>Souvent, nous voulons prévoir plus loin dans le futur qu’une seule étape temporelle. Dans un exercice étendu, vous adapterez le <code>dataset</code> et le modèle pour permettre une prédiction à plusieurs étapes.</p>
<div id="section-changements-requis" class="section level4">
<h4>Changements requis</h4>
<div id="section-dataset" class="section level5">
<h5><code>dataset</code></h5>
<p>Dans le <code>dataset</code>, nous distinguons maintenant le nombre de pas de temps sur lequel baser l’apprentissage (<code>n_timesteps</code>), et le nombre de pas de temps à prévoir (<code>n_forecast</code>).</p>
<p>Dans <code>.getitem()</code>, le tenseur retourné en <code>x</code> reste inchangé, tandis qu’en <code>y</code>, nous retournons les valeurs <code>n_forecast</code> immédiatement après la dernière composante de <code>x</code>.</p>
<p>En raison de la nouvelle logique, <code>.length()</code>devra également être modifié.</p>
</div>
<div id="section-modèle-2" class="section level5">
<h5>Modèle</h5>
<p>Le modèle doit maintenant produire <code>n_forecast</code> values. Le moyen le plus simple d’y parvenir est de faire en sorte que la couche linéaire finale renvoie <code>n_forecast</code> valeurs prévisionnelles au lieu d’une seule. Cependant, en fonction des données, cela peut ou non donner des performances satisfaisantes.</p>
<p>Au lieu de cela, nous pouvons enchaîner plusieurs couches linéaires, reliées par des non-linéarités. Autrement dit, nous aurons un “réseau dans le réseau” - le GRU sera suivi d’un réseau à propagation directe, également appelé <em>perceptron multicouche</em> (<em>MLP</em>).</p>
<p>Dans cette deuxième approche, nettement plus puissante, il est facile de s’adapter de manière excessive à l’ensemble de formation. Pour contrer l’adaptation excessive, nous ajoutons une couche <em>dropout</em>. Avec le dropout, une quantité configurable d’aléatoire est ajoutée durant la période d’entrâinement (mais pas durant celles de validation et de test). Techniquement, ceci est réalisé en mettant à zéro de manière aléatoire la fraction souhaitée d’éléments dans le tenseur d’entrée de la couche.</p>
<p>Vous trouverez ci-dessous des instructions pour mettre en œuvre la deuxième solution.</p>
</div>
</div>
<div id="section-exercice-partie-1-adaptation-du-dataset" class="section level4">
<h4>Exercice partie 1 : Adaptation du <code>dataset</code></h4>
<p>Commencez par effectuer les changements mentionnés ci-dessus dans le <code>dataset</code>.</p>
<div class="tutorial-exercise" data-label="multi-step-ds" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>elec_dataset &lt;- dataset(
  name = &quot;elec_dataset&quot;,
  
  initialize = function(x, n_timesteps, n_forecast) {
    
  },
  
  .getitem = function(i) {
    
  
  },
  
  .length = function() {
    
  }
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="multi-step-ds-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>elec_dataset &lt;- dataset(
  name = &quot;elec_dataset&quot;,
  
  initialize = function(x, n_timesteps, n_forecast) {
    
    self$n_timesteps &lt;- n_timesteps
    self$n_forecast &lt;- n_forecast
    self$x &lt;- torch_tensor((x - train_mean) / train_sd)

  },
  
  .getitem = function(i) {
    
    start &lt;- i
    end &lt;- start + self$n_timesteps - 1
    pred_length &lt;- self$n_forecast
    
    list(
      x = self$x[start:end],
      y = self$x[(end + 1):(end + pred_length)]$squeeze(2)
    )
    
  },
  
  .length = function() {
    length(self$x) - self$n_timesteps - self$n_forecast + 1
  }
)</code></pre>
</div>
<p>Une fois que vous avez mis à jour la définition du <code>dataset</code>, vous devez recréer <code>train_ds</code> et <code>valid_ds</code>. Choisissez un nombre pour la fenêtre de prévision (<code>n_forecast</code>), par exemple quatorze jours :</p>
<pre class="r"><code>n_timesteps &lt;- 7 * 2
n_forecast &lt;- 7 * 2 

train_ds &lt;- elec_dataset(elec_train, n_timesteps, n_forecast)

valid_ds &lt;- elec_dataset(elec_valid, n_timesteps, n_forecast)</code></pre>
<p>Pour vérifier votre implémentation, assurez-vous que</p>
<pre class="r"><code>length(train_ds)
train_ds[1]</code></pre>
<p>fonctionne correctement.</p>
<p>Pour passer à l’étape suivante, vous devez également recréer les <code>dataloader</code>s.</p>
<pre class="r"><code>batch_size &lt;- 32
train_dl &lt;- train_ds %&gt;% dataloader(batch_size = batch_size, shuffle = TRUE)

valid_dl &lt;- valid_ds %&gt;% dataloader(batch_size = batch_size)</code></pre>
</div>
<div id="section-exercice-partie-2-adaptation-du-modèle" class="section level4">
<h4>Exercice partie 2 : Adaptation du modèle</h4>
<p>Maintenant, adaptez le modèle, dans le sens décrit ci-dessus.</p>
<div class="tutorial-exercise" data-label="multi-step-model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>model &lt;- nn_module(
  
  # pour éviter de coder en dur des valeurs spécifiques, vous pouvez ajouter d&#39;autres &quot;hparams&quot; ici
  initialize = function(input_size, hidden_size, ...) {
    
    self$rnn &lt;- nn_gru(
        input_size = input_size,
        hidden_size = hidden_size,
        batch_first = TRUE
      )
    
    # un perceptron multicouche, utilisant nn_dropout avant la couche de sortie
    self$mlp &lt;- nn_sequential(
      
      
      
    )
    
  },
  
  forward = function(x) {
    
    
    
  }
  
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="multi-step-model-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>model &lt;- nn_module(
  
  initialize = function(input_size, hidden_size, linear_size, output_size, dropout = 0) {
    
    self$rnn &lt;- nn_gru(
        input_size = input_size,
        hidden_size = hidden_size,
        batch_first = TRUE
      )
    
    self$mlp &lt;- nn_sequential(
      nn_linear(hidden_size, linear_size),
      nn_relu(),
      nn_dropout(dropout),
      nn_linear(linear_size, output_size)
    )
    
  },
  
  forward = function(x) {
    
    x &lt;- self$rnn(x)
    # pass last timestep of RNN output to MLP
    x[[1]][ ,-1, ..] %&gt;% 
      self$mlp()
    
  }
  
)</code></pre>
</div>
</div>
<div id="section-exercice-partie-3-formation" class="section level4">
<h4>Exercice partie 3 : Formation</h4>
<p>L’entraînement ressemble beaucoup à l’exercice précédent, à part le fait que vous devrez définir plus de <code>hparams</code>.</p>
<div class="tutorial-exercise" data-label="multi-step-fit" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>#fitted &lt;-</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="multi-step-fit-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>fitted &lt;- model %&gt;%
  setup(
    loss = nn_mse_loss(),
    optimizer = optim_adam,
    metrics = list(
     luz_metric_mse()
    )
  ) %&gt;%
  set_hparams(input_size = 1, hidden_size = 64, linear_size = 128,
             output_size = n_forecast, dropout = 0.5) %&gt;%
  fit(train_dl, epochs = 20, valid_data = valid_dl, verbose = TRUE)</code></pre>
</div>
<p>Une fois que vous avez terminé, voici un code pour visualiser une sélection de séquences de prévisions (n’hésitez pas à l’adapter).</p>
<pre class="r"><code>preds &lt;- predict(fitted, test_dl)
preds &lt;- as.matrix(preds)</code></pre>
<pre class="r"><code>test_pred1 &lt;- preds[1, ]
test_pred1 &lt;- c(rep(NA, n_timesteps), test_pred1, rep(NA, nrow(vic_elec_test) - n_timesteps - n_forecast))

test_pred2 &lt;- preds[21, ]
test_pred2 &lt;- c(rep(NA, n_timesteps + 20), test_pred2, rep(NA, nrow(vic_elec_test) - 20 - n_timesteps - n_forecast))

test_pred3 &lt;- preds[41, ]
test_pred3 &lt;- c(rep(NA, n_timesteps + 40), test_pred3, rep(NA, nrow(vic_elec_test) - 40 - n_timesteps - n_forecast))

test_pred4 &lt;- preds[61, ]
test_pred4 &lt;- c(rep(NA, n_timesteps + 60), test_pred4, rep(NA, nrow(vic_elec_test) - 60 - n_timesteps - n_forecast))

test_pred5 &lt;- preds[81, ]
test_pred5 &lt;- c(rep(NA, n_timesteps + 80), test_pred5, rep(NA, nrow(vic_elec_test) - 80 - n_timesteps - n_forecast))

preds_ts &lt;- vic_elec_test %&gt;% 
  add_column(
    ex_1 = test_pred1 * train_sd + train_mean,
    ex_2 = test_pred2 * train_sd + train_mean,
    ex_3 = test_pred3 * train_sd + train_mean,
    ex_4 = test_pred4 * train_sd + train_mean,
    ex_5 = test_pred5 * train_sd + train_mean) %&gt;%
  pivot_longer(-Date) %&gt;%
  update_tsibble(key = name)


preds_ts %&gt;%
  autoplot() +
  scale_color_hue(h = c(80, 300), l = 70) +
  theme_minimal()</code></pre>
</div>
</div>
</div>
<div id="section-questions-et-réponses" class="section level2">
<h2>Questions et réponses</h2>
<p>Des questions ?</p>
<p>Restez en contact :</p>
<ul>
<li><p>GitHub : <a href="https://github.com/torch">torch</a>, <a href="https://github.com/luz">luz</a>, …</p></li>
<li><p>Discord : <a href="https://discord.com/invite/s3D5cKhBkx">torch for R</a></p></li>
<li><p>Blog : <a href="https://blogs.rstudio.com/ai/">RStudio AI Blog</a></p></li>
</ul>
Merci de votre attention ! 
<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
library(torch)
library(luz)
library(torchvision)
library(tidyverse)
library(tsibble)
library(tsibbledata)
library(lubridate)
library(fable)
library(feasts)
library(zeallot)

knitr::opts_chunk$set(echo = FALSE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::session_stop_event(session)
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors1-code-editor`)), session)
output$`tutorial-exercise-tensors1-output` <- renderUI({
  `tutorial-exercise-tensors1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors2-code-editor`)), session)
output$`tutorial-exercise-tensors2-output` <- renderUI({
  `tutorial-exercise-tensors2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors3-code-editor`)), session)
output$`tutorial-exercise-tensors3-output` <- renderUI({
  `tutorial-exercise-tensors3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors4-code-editor`)), session)
output$`tutorial-exercise-tensors4-output` <- renderUI({
  `tutorial-exercise-tensors4-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors5-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors5-code-editor`)), session)
output$`tutorial-exercise-tensors5-output` <- renderUI({
  `tutorial-exercise-tensors5-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-autograd-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-autograd-code-editor`)), session)
output$`tutorial-exercise-autograd-output` <- renderUI({
  `tutorial-exercise-autograd-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-modules-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-modules-code-editor`)), session)
output$`tutorial-exercise-modules-output` <- renderUI({
  `tutorial-exercise-modules-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-custom-callback-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-custom-callback-code-editor`)), session)
output$`tutorial-exercise-custom-callback-output` <- renderUI({
  `tutorial-exercise-custom-callback-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-custom-metric-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-custom-metric-code-editor`)), session)
output$`tutorial-exercise-custom-metric-output` <- renderUI({
  `tutorial-exercise-custom-metric-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-multi-step-ds-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-multi-step-ds-code-editor`)), session)
output$`tutorial-exercise-multi-step-ds-output` <- renderUI({
  `tutorial-exercise-multi-step-ds-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-multi-step-model-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-multi-step-model-code-editor`)), session)
output$`tutorial-exercise-multi-step-model-output` <- renderUI({
  `tutorial-exercise-multi-step-model-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-multi-step-fit-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-multi-step-fit-code-editor`)), session)
output$`tutorial-exercise-multi-step-fit-output` <- renderUI({
  `tutorial-exercise-multi-step-fit-result`()
})
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.8"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98]}},"value":[{"type":"character","attributes":{},"value":["anytime","assertthat","backports","base","bit","bit64","broom","bslib","callr","cellranger","cli","colorspace","compiler","coro","crayon","datasets","DBI","dbplyr","digest","distributional","dplyr","ellipsis","evaluate","fable","fabletools","fansi","farver","fastmap","feasts","forcats","fs","generics","ggplot2","glue","graphics","grDevices","grid","gtable","haven","hms","htmltools","htmlwidgets","httpuv","httr","jquerylib","jsonlite","knitr","later","learnr","lifecycle","lubridate","luz","magrittr","markdown","methods","mime","modelr","munsell","pillar","pkgconfig","processx","promises","ps","purrr","R6","Rcpp","readr","readxl","reprex","rlang","rmarkdown","rprojroot","rstudioapi","rvest","sass","scales","shiny","stats","stringi","stringr","tibble","tidyr","tidyselect","tidyverse","tools","torch","torchvision","tsibble","tsibbledata","utf8","utils","vctrs","withr","xfun","xml2","xtable","yaml","zeallot"]},{"type":"character","attributes":{},"value":["0.3.9","0.2.1","1.2.1","4.0.5","4.0.4","4.0.5","0.7.6","0.2.5.1","3.7.0","1.1.0","2.5.0","2.0-1","4.0.5","1.0.1","1.4.1","4.0.5","1.1.1","2.1.1","0.6.27","0.2.2","1.0.6","0.3.2","0.14","0.3.1","0.3.1","0.5.0","2.1.0","1.1.0","0.2.1","0.5.1","1.5.0","0.1.0","3.3.3","1.4.2","4.0.5","4.0.5","4.0.5","0.3.0","2.4.1","1.1.0","0.5.1.1","1.5.3","1.6.1","1.4.2","0.1.4","1.7.2","1.33","1.2.0","0.10.1","1.0.0","1.7.10","0.0.0.9000","2.0.1","1.1","4.0.5","0.10","0.1.8","0.5.0","1.6.1","2.0.3","3.5.2","1.2.0.1","1.6.0","0.3.4","2.5.0","1.0.6","1.4.0","1.3.1","2.0.0","0.4.11","2.8","2.0.2","0.13","1.0.0","0.4.0","1.1.1","1.6.0","4.0.5","1.6.2","1.4.0","3.1.2","1.1.3","1.1.1","1.3.1","4.0.5","0.3.0.9004","0.3.0.9000","1.0.1","0.3.0","1.2.1","4.0.5","0.3.8","2.4.2","0.23","1.3.2","1.8-4","2.2.1","0.1.0"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Débuter avec torch</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
